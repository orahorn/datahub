# Производительность и распараллеливание

Параллельные вычисления появились в 20 веке, однако массовое внедрение
получили лишь в веке следующим. Это связано с тем, что на промышленный
поток поставили производство микросхем содержащих по нескольку процессорных
ядер и реализация нескольких конвейеров команд в одном процессорном ядре.
Эти машины стали называть
[Компьютеры пятого поколения](https://ru.wikipedia.org/wiki/%D0%9A%D0%BE%D0%BC%D0%BF%D1%8C%D1%8E%D1%82%D0%B5%D1%80%D1%8B_%D0%BF%D1%8F%D1%82%D0%BE%D0%B3%D0%BE_%D0%BF%D0%BE%D0%BA%D0%BE%D0%BB%D0%B5%D0%BD%D0%B8%D1%8F).


Также мощный импульс к этому дала технология выполнения вычислений общего
назначения на микросхемах графических ускорителей.
Речь пойдёт о таких технологиях, как NVidia [CUDA](https://ru.wikipedia.org/wiki/CUDA), [OpenACC](https://ru.wikipedia.org/wiki/OpenACC).
AMD продвигает стандарт [OpenCL](https://ru.wikipedia.org/wiki/OpenCL).

Всё сказанное относится к распараллеливанию в рамках контроля на одном
вычислительном узле, одним или несколькими CPU в одной памяти, за искл. ускорителей, но находящихся в системе на одной шине
(как правило семейства [PCI](https://ru.wikipedia.org/wiki/PCI)).
Но параллельные вычисления можно организовывать и на группировке узлов,
соединённых локальной и даже глобальной сетью.
Подобный подход принято называть - распределёнными вычислениями.
Тут большую роль могут сыграть такие платформы,
как Open Telecom Platform ([OTP](https://ru.wikipedia.org/wiki/Open_Telecom_Platform)) с языком программирования Erlang или популярную в наши дни платформу Node.JS практикующую идеологию асинхронного неблокирующего программирования на языке JavaScript.

## Пионеры параллельной процессорной обработки данных

Одной из первых компаний, в основу бизнеса которых было
поставлено производство компьютерных систем с распределёнными по
узлам вычислений - была Tandem Computers в 1974.
Позже её поглотила ненадолго компания Compaq (не лучших немного лет
по мнению сотрудников).
А позже всё это вылилось в компанию HP, поглотившую Compaq.
Ну а в наше время - в расколотую половину - HPE.

Подобные системы до сих пор производятся под брендом NonStop.
Основными отраслями где эксплуатируются NonStop-системы являются:

* Банковские транзакции (перевод средств между счетами)
* Телекоммуникационные сети (биллинг реального времени и др. услуги IN)
* Биокомпьютинг и телемедицина
* Новые направление
	- Блокчейн сети
	- облачные вычисления

По сути HPE NonStop сервера относят к классу массивно-параллельной архитектуры,
в которых память разделена даже между центральными процессорами на одной шине,
носившей название [ServerNet](https://en.wikipedia.org/wiki/ServerNet_(Tandem)). В последних вариантах машин произошёл
переход на более новый тип соединений - это [InfiniBand](https://ru.wikipedia.org/wiki/InfiniBand).
Также на подобную шину вешаются адаптеры ввода-вывода.


### Базы данных NonStop серверов

**Enscribe** - одни из первых БД, представляющие из себя структурированные индексированные файлы (аналогично Berkley Database)
с набором соответствующего программного обеспечения (ПО) - это ПО называется TMF - Transaction Management Facility. 

**SQL MP** - первое поколение реляционных СУБД. Считается устаревшим и не развивается.

**SQL MX** - NonStop SQL/MX - второе и современное поколение СУБД. Актуальное, постоянно развивается
и в нём активно исправляются ошибки.
Для журналирования транзакций SQL базы данных используют подсистему TMF.
Реплицирование происходит средствами RDF - ПО Remote Database Facility.

## Ветвление процессов

С самого начала создания многозадачных вычислительных систем,
предполагалось, что на них почти одновременно можно запустить
несколько задач или процессов, а потом они через какой-то
интервал времени будут завершаться, в зависимости от алгоритмов
и набора обрабатываемых данных.

На самом деле каждая из загруженных на выполнения задач
в таких системах обрабатывалась одним процессором (с одним потоком 
команд) последовательно (поочерёдно, с приоритетами) в разное время.
Т.о. каждому процессу выделялся определённый квант времени, в течении которого 
выполнялась часть одной задачи, а в следующий квант времени - выполнялась следующая по приоритету задача (процесс).
Т.е. такие системы назывались
[Системами с разделением времени](https://ru.wikipedia.org/wiki/%D0%A0%D0%B0%D0%B7%D0%B4%D0%B5%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5_%D0%B2%D1%80%D0%B5%D0%BC%D0%B5%D0%BD%D0%B8). Они в свою очеред делились на :

* Совместная или кооперативная многозадачность - Win 3.\*, 9x
* [системы с вытесняющей многозадачностью](https://ru.wikipedia.org/wiki/%D0%92%D1%8B%D1%82%D0%B5%D1%81%D0%BD%D1%8F%D1%8E%D1%89%D0%B0%D1%8F_%D0%BC%D0%BD%D0%BE%D0%B3%D0%BE%D0%B7%D0%B0%D0%B4%D0%B0%D1%87%D0%BD%D0%BE%D1%81%D1%82%D1%8C) - WinNT, UNIX


В операционных системах Unix новые отдельные задачи называются процессами,
они порождаются другими процессами с помощью системного вызова [fork(2)](https://ru.wikipedia.org/wiki/Fork),
после вызова функции (после возврата из неё) происходит исполнение точно такого же кода в другом процессе.
Чтобы это был другой код, можно воспользоваться функцией exec  - которая замещает текущий процесс.

С появлением многоядерных многопроцессорных систем с общей памятью, паралелльные вычисления стали по-настоящему одновременными
что дало возможность повышать производительность при решении определённого класса задач.


## Многопоточный интерфейс программирования

Интерфейс создания нескольких потоков из одного процесса происходит с помощью библиотеки pthread.

## Промышленный стандарт HPC

Аббревиатура HPC  расшифровывается, как High Performance Computing.
Т.е. это суперкомпьютеры, вычислительная мощность которых, значительно больше
основного количества компьютеров на планете.
Есть рейтинги, и топы производительности, например рейтинг [Top500](https://ru.wikipedia.org/wiki/Top500).
Скорость вычислений достигается, не только повышением тактовой частоты процессоров, 
но и добавлением ядер, как внутри одной микросхемы, так и добавлением процессоров на одну плату,
а также создание вычислительных блоков на одной шине либо соединённых сверхвысокопроизводителными
соединениями, такими, как [InfiniBand](https://ru.wikipedia.org/wiki/InfiniBand).
Подобные соединения между вычислительными узлами, называются интерконнектами.
А сами узлы - это элементами вычислительного кластера.
Следует понимать, что главных численных характеристик две:

* количество выполненых операций за некоторый заданный интервал времени - производительность кластера
* среднее время выполнения одной операции - т.н. время отклика кластера

Помимо этого есть т.н. понятие GRID-компьютинга (от слова "решётка"), это когда узлы кластера разбросаны территориально
по сети Интернет и технически нет возможности соединять их быстрыми каналами. Но эти узлы имеют централизованное управление,
что позволяет на них передать и распределить части данных одной задачи, а потом результат собрать в единое целое.

У компании Microsoft есть специальная версия ОС [Windows HPC Server 2008](https://ru.wikipedia.org/wiki/Windows_HPC_Server_2008).

Для тестирования производительности есть ПО [HPC Challenge Benchmark](https://ru.wikipedia.org/wiki/HPC_Challenge_Benchmark) .
Это некий комплект тестов, которые решают синтетические математические задачи, сравнивают результаты с эталоном
и засекается время прогона теста. Т.е. это т.н. нагрузочное тестирование.
В Debian/Ubuntu дистрибутиве есть для этого специальный пакет:

	apt show hpcc



## Стандарт библиеотек MPI

MPI используется в языках программирования C/C++/Fortran.
Она используется для формирования вычислительного кластера.
Вышло три стандарта.
Используется принцип разделяемой памяти и передача данных между процессам в виде сообщений.
Специальным образом собирается программа, части которой общаются через код-коммуникатор.
Также может быть использована техника удалённого доступа к вычисляемой памяти.


### MPICH

[MPICH](https://www.mpich.org/) старая библиотека параллельных вычислений.
Уже использует третью версию.
Компиляцию программ выполняет обёртка mpicc, а запускает программа mpiexec.

### OpenMPI

С появлением многопроцессорных и многоядерных систем
была реализована библиотека [Open MPI](https://en.wikipedia.org/wiki/Open_MPI), задействующая доступ к разделяемой памяти.
Помимо C++ есть поддержка Java.

Простейшая программа [hello_c.c](https://github.com/open-mpi/ompi/blob/master/examples/hello_c.c):

```c
/*
 * Copyright (c) 2004-2006 The Trustees of Indiana University and Indiana
 *                         University Research and Technology
 *                         Corporation.  All rights reserved.
 * Copyright (c) 2006      Cisco Systems, Inc.  All rights reserved.
 *
 * Sample MPI "hello world" application in C
 */

#include "mpi.h"
#include <stdio.h>

int main(int argc, char *argv[])
{
    int rank, size, len;
    char version[MPI_MAX_LIBRARY_VERSION_STRING];

    MPI_Init(&argc, &argv);
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);
    MPI_Get_library_version(version, &len);
    printf("Hello, world, I am %d of %d, (%s, %d)\n", rank, size, version, len);
    MPI_Finalize();

    return 0;
}
```

Компилируем в исполнимый модуль:

	mpicc.openmpi hello_c.c -o hello_e

Запускаем модуль:

```
$ mpiexec.openmpi -n 5 hello_e
Hello, world, I am 0 of 5, (Open MPI v2.1.1, package: Open MPI buildd@lcy01-amd64-009 Distribution, ident: 2.1.1, repo rev: v2.1.0-100-ga2fdb5b, May 10, 2017, 130)
Hello, world, I am 1 of 5, (Open MPI v2.1.1, package: Open MPI buildd@lcy01-amd64-009 Distribution, ident: 2.1.1, repo rev: v2.1.0-100-ga2fdb5b, May 10, 2017, 130)
Hello, world, I am 3 of 5, (Open MPI v2.1.1, package: Open MPI buildd@lcy01-amd64-009 Distribution, ident: 2.1.1, repo rev: v2.1.0-100-ga2fdb5b, May 10, 2017, 130)
Hello, world, I am 4 of 5, (Open MPI v2.1.1, package: Open MPI buildd@lcy01-amd64-009 Distribution, ident: 2.1.1, repo rev: v2.1.0-100-ga2fdb5b, May 10, 2017, 130)
Hello, world, I am 2 of 5, (Open MPI v2.1.1, package: Open MPI buildd@lcy01-amd64-009 Distribution, ident: 2.1.1, repo rev: v2.1.0-100-ga2fdb5b, May 10, 2017, 130)

```


## Parallel Virtual Machine

## Общие вычисления на графических ускорителях GPGPU

## Fortran HPC

## Библиеотека OpenCL



## OpenACC

## Концепция неблокирующего, ассинхронно/ожидающего программирования

Само понятие [Async/await](https://en.wikipedia.org/wiki/Async/await) программирования появилась, когда
классические Unix-API ядра с семафорами и языком Си вызвали потребность реализовать
накопленное в синтаксисе уже других более современны языков программирования:
C#, C++, Python, F#, Julia, Kotlin, Rust, JavaScript, Scala и Swift.

Есть классическая библиотека [libaio](https://pagure.io/libaio) для поддержки асинхронного ввода-вываода на 
Linux.

Установка на Debian/Ubuntu ориентированных дистрибутивах:

```
sudo apt install libaio-dev
sudo apt install python3-async
sudo apt install node-async
sudo apt install nlibfuture-asyncawait-perl
```


## Источники

* Блог Хабра:
	- [OpenCL в повседневных задачах](https://habr.com/ru/company/amd/blog/388421/)
	- [Heterogeneous System Architecture или о встрече CPU и GPU](https://habr.com/ru/company/amd/blog/387439/)
* [Семейство систем HPE NonStop](https://www.hpe.com/ru/ru/servers/nonstop.html) - официальный сайт
	- [NonStop SQL](https://ru.bmstu.wiki/NonStop_SQL)
	- [Массово-параллельная архитектура](https://ru.wikipedia.org/wiki/%D0%9C%D0%B0%D1%81%D1%81%D0%BE%D0%B2%D0%BE-%D0%BF%D0%B0%D1%80%D0%B0%D0%BB%D0%BB%D0%B5%D0%BB%D1%8C%D0%BD%D0%B0%D1%8F_%D0%B0%D1%80%D1%85%D0%B8%D1%82%D0%B5%D0%BA%D1%82%D1%83%D1%80%D0%B0)
* [Основные классы современных параллельных компьютеров](https://parallel.ru/computers/classes.html)
* [Многопроцессорность](https://ru.wikipedia.org/wiki/%D0%9C%D0%BD%D0%BE%D0%B3%D0%BE%D0%BF%D1%80%D0%BE%D1%86%D0%B5%D1%81%D1%81%D0%BE%D1%80%D0%BD%D0%BE%D1%81%D1%82%D1%8C)
* [Симметричная многопроцессорность](https://ru.wikipedia.org/wiki/%D0%A1%D0%B8%D0%BC%D0%BC%D0%B5%D1%82%D1%80%D0%B8%D1%87%D0%BD%D0%B0%D1%8F_%D0%BC%D0%BD%D0%BE%D0%B3%D0%BE%D0%BF%D1%80%D0%BE%D1%86%D0%B5%D1%81%D1%81%D0%BE%D1%80%D0%BD%D0%BE%D1%81%D1%82%D1%8C)
* [Параллельные вычислительные системы](https://ru.wikipedia.org/wiki/%D0%9F%D0%B0%D1%80%D0%B0%D0%BB%D0%BB%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5_%D0%B2%D1%8B%D1%87%D0%B8%D1%81%D0%BB%D0%B8%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5_%D1%81%D0%B8%D1%81%D1%82%D0%B5%D0%BC%D1%8B)
* [Распределённые вычисления](https://ru.wikipedia.org/wiki/%D0%A0%D0%B0%D1%81%D0%BF%D1%80%D0%B5%D0%B4%D0%B5%D0%BB%D1%91%D0%BD%D0%BD%D1%8B%D0%B5_%D0%B2%D1%8B%D1%87%D0%B8%D1%81%D0%BB%D0%B5%D0%BD%D0%B8%D1%8F)
* [Параллельные вычисления](https://ru.wikipedia.org/wiki/%D0%9F%D0%B0%D1%80%D0%B0%D0%BB%D0%BB%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5_%D0%B2%D1%8B%D1%87%D0%B8%D1%81%D0%BB%D0%B5%D0%BD%D0%B8%D1%8F)
* [Параллельные вычисления в оптике  и оптоинформатике](https://books.ifmo.ru/file/pdf/558.pdf)
* [Технологии построения и использования кластерных систем](https://intuit.ru/studies/courses/542/398/info)
* [#hpenonstop на Youtube](https://www.youtube.com/hashtag/hpenonstop)
* [HPE NonStop RDF System Management Manual](https://support.hpe.com/hpesc/public/docDisplay?docId=emr_na-c03417961) (RDF Update 13)

